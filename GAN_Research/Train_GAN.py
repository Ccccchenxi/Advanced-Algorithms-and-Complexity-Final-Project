import os
import time

import numpy as np
import pandas as pd

import torch
import torch.nn as nn
import torch.optim as optim
from sklearn.preprocessing import StandardScaler

from torch.utils.data import Dataset, DataLoader
from torch import from_numpy
from torch.utils.tensorboard import SummaryWriter



save_dir = './runs'

save_path = os.path.join(save_dir, time.strftime("%Y-%m-%d-%H-%M-%S", time.localtime()))

os.makedirs(save_path, exist_ok=True)

writer = SummaryWriter(os.path.join(save_path, 'logs'))

from Discriminator import SimpleConvDisc

from Generator import SimpleConvGen


batch_size=2 # 100 pieces of data in a batch, 2 batch models at a time.

epochs = 200  #Iterative effects 200 best results

real_label = torch.FloatTensor(batch_size*7).cuda()

real_label.fill_(1)  # Filled with 1's, i.e. true labels are 1's


g_real_label = torch.FloatTensor(batch_size*7).cuda()

g_real_label.fill_(1)  # Filled with 1's, i.e. true labels are 1's

fake_label = torch.FloatTensor(batch_size*7).cuda()

fake_label.fill_(0)
class Train_DiabetesDataset(Dataset):
    def __init__(self):
        a = np.loadtxt('./data/UAQ.csv', delimiter=',', dtype=np.float32)

        #print(a.shape)

        x = np.reshape(a, (-1, 100, 7))

        #print(x.shape)
        self.len = x.shape[0]

        self.x_data = from_numpy(x)

    def __getitem__(self, index):
        return self.x_data[index]

    def __len__(self):
        return self.len

train_dataset = Train_DiabetesDataset()
train_loader = DataLoader(dataset=train_dataset,
                          batch_size=batch_size,
                          shuffle=True)


D = SimpleConvDisc(100).cuda()

G = SimpleConvGen().cuda()


# Initialise the optimiser and loss function
d_learning_rate = 0.01 # Define the learning rate of the generator and the discriminator respectively
g_learning_rate = 0.001


loss_func = nn.BCELoss()  # - [p * log(q) + (1-p) * log(1-q)] Using bce as a loss function Using BCE as a loss function in generative adversarial networks


optimiser_D = optim.Adam(D.parameters(), lr=d_learning_rate) # Define optimiser for gradient descent optimisation using Adam's algorithm Overall network model uses Adam as optimiser for gradient descent
optimiser_G = optim.Adam(G.parameters(), lr=g_learning_rate)


for epoch in range(epochs):
        # 1 Training D with real data
    for i, (real_data) in enumerate(train_loader):
            optimiser_D.zero_grad()

            real_data = np.reshape(real_data, (-1, 7))

            #print(real_data.shape,"real data")

            scaler = StandardScaler()  # Normalisation of data prior to input into the model

            scaler.fit(real_data)

            real_data = scaler.transform(real_data)  # Standardised matrix

            real_data = np.reshape(real_data, (-1, 100, 7))

            real_data = from_numpy(real_data)

            real_data = real_data.cuda().float()

            #print(real_data.shape,"real_data.shape")

            #print("Real Data--[{}]]".format(real_data))
            # 1.1 real_data is input to D, and d_real is obtained.
            d_real = D(real_data)

            d_real = torch.reshape(d_real, [-1])

            #print(d_real.shape,"d_real.shape")

            loss_d_real = loss_func(d_real, real_label)

            #2 Use fake data to train D
            noise_ = np.random.normal(0, 1, (batch_size,100, 7))
            # Noise generated by random sampling from a normal distribution with 0 as origin and 1 as width

            noise_ = ((torch.from_numpy(noise_)).float())

            noise_ =noise_.cuda()  # Convert to tensor for use pytorch

            Gnoise=G(noise_)

           # print(Gnoise.shape,"Gnoise")

            d_fake=D(Gnoise.detach())

            d_fake = torch.reshape(d_fake, [-1])

            #print(d_fake.shape, "d_fake.shape")

            loss_d_fake=loss_func(d_fake, fake_label)

            loss_d=loss_d_fake+loss_d_real

            loss_d.backward(retain_graph=True)

            optimiser_D.step()


            #2train G
            optimiser_G.zero_grad()

            d_g_fake= D(Gnoise)

            d_g_fake = torch.reshape(d_g_fake, [-1])

            #print(d_g_fake.shape, "d_g_fake.shape")
            loss_G = loss_func(d_g_fake, g_real_label)

            loss_G.backward(retain_graph=True)

            optimiser_G.step()

            iteration_now = epoch * len(train_loader) + i

            print("Epoch--[{} / {}], Loss_Discriminator--[{}], Loss_Generator--[{}]".format(epoch, epochs,loss_d_fake,loss_G,))

            if i % epochs == 0:
                noise_2 = np.random.normal(0, 1, (6, 100, 7))
                # Noise generated by random sampling from a normal distribution of 0 for the origin, 1 for the width, which is used to control the amount of data generated here is 6 Ã— 100 = 600 that is, 600 generated
                noise_2 = ((torch.from_numpy(noise_2)).float())

                noise_2 = noise_2.cuda()

                constructed = G(noise_2)

                constructed = (constructed.cuda()).detach().cpu().numpy()

                constructed = np.reshape(constructed, (-1,7))

               # print(constructed.shape,"constructed.shape")
                np.set_printoptions(threshold=np.inf)
                #print("Generate Data--[{}]]".format(constructed))
                constructed = scaler.inverse_transform(constructed)  # Conversion of standardised data to raw data

                file_path = r"GenerateUAQ.xlsx"  # Location to save to and file name, file type

                df = pd.DataFrame(constructed)

                df.to_excel(file_path)

    writer.add_scalar('Loss_Discriminator', loss_d_fake, epoch)

    writer.add_scalar('Loss_Generator', loss_G, epoch)
